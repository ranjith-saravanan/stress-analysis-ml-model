{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf900103",
   "metadata": {},
   "source": [
    "# ðŸ§  Social Media Detox Effect Analyzer\n",
    "\n",
    "**A comprehensive machine learning framework analyzing the relationship between social media abstinence and mental health outcomes using advanced analytics including correlation analysis, regression modeling, user segmentation clustering, and LSTM-based time series prediction.**\n",
    "\n",
    "## ðŸ“Š Project Overview\n",
    "\n",
    "This project combines **time series prediction**, **clustering**, **regression analysis**, and **deep learning** to create a real-time mental health monitoring system. It's a perfect advanced portfolio piece demonstrating mastery of multiple ML techniques.\n",
    "\n",
    "### Key Features\n",
    "- Multi-modal correlation and regression analysis\n",
    "- User segmentation through K-Means and DBSCAN clustering\n",
    "- Time series forecasting with LSTM neural networks\n",
    "- Real-time prediction capabilities\n",
    "- Personalized recommendations based on user phenotypes\n",
    "\n",
    "### Dataset\n",
    "- **Source**: Mental Health and Social Media Balance Dataset\n",
    "- **Size**: 500 users with comprehensive mental health metrics\n",
    "- **Features**: Age, Gender, Daily Screen Time, Sleep Quality, Stress Level, Days Without Social Media, Exercise Frequency, Social Media Platform, Happiness Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a243eea",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from 'c:\\Users\\RANJITH S\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Statistical Analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Machine Learning - Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit\n",
    "\n",
    "# Machine Learning - Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Time Series\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754468df",
   "metadata": {},
   "source": [
    "# ðŸ“¥ Phase 1: Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6d295",
   "metadata": {},
   "source": [
    "# ðŸ“Š Phase 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fdde16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Distribution Analysis\n",
    "print(\"ðŸ“Š EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "fig.suptitle('Feature Distributions', fontsize=16, fontweight='bold')\n",
    "\n",
    "numeric_cols = ['Age', 'Daily_Screen_Time(hrs)', 'Sleep_Quality(1-10)', \n",
    "                'Stress_Level(1-10)', 'Days_Without_Social_Media', \n",
    "                'Exercise_Frequency(week)', 'Happiness_Index(1-10)']\n",
    "\n",
    "for idx, feature in enumerate(numeric_cols):\n",
    "    row = idx // 4\n",
    "    col = idx % 4\n",
    "    axes[row, col].hist(df[feature], bins=20, edgecolor='black', alpha=0.7)\n",
    "    axes[row, col].set_title(f'{feature}')\n",
    "    axes[row, col].set_xlabel('Value')\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/01_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 2.2 Categorical Variables Analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Gender distribution\n",
    "gender_counts = df['Gender'].value_counts()\n",
    "axes[0].bar(gender_counts.index, gender_counts.values, alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Gender Distribution')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Social Media Platform distribution\n",
    "platform_counts = df['Social_Media_Platform'].value_counts()\n",
    "axes[1].bar(platform_counts.index, platform_counts.values, alpha=0.7, edgecolor='black')\n",
    "axes[1].set_title('Social Media Platform Distribution')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/02_categorical_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Distribution analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec34c511",
   "metadata": {},
   "source": [
    "# ðŸ”— Phase 3: Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea516bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Correlation Matrix\n",
    "print(\"ðŸ”— CORRELATION ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate correlations between numerical variables\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, fmt='.2f', mask=mask)\n",
    "plt.title('Correlation Matrix: All Numerical Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/03_correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 3.2 Focus on Key Relationships\n",
    "print(\"\\nðŸŽ¯ Key Correlations with Mental Health Outcomes:\")\n",
    "\n",
    "# Stress Level correlations\n",
    "stress_correlations = correlation_matrix['Stress_Level(1-10)'].sort_values(ascending=False)\n",
    "print(\"\\nCorrelations with Stress Level:\")\n",
    "for var, corr in stress_correlations.items():\n",
    "    if var != 'Stress_Level(1-10)':\n",
    "        print(f\"  {var}: {corr:.4f}\")\n",
    "\n",
    "# Happiness Index correlations\n",
    "happiness_correlations = correlation_matrix['Happiness_Index(1-10)'].sort_values(ascending=False)\n",
    "print(\"\\nCorrelations with Happiness Index:\")\n",
    "for var, corr in happiness_correlations.items():\n",
    "    if var != 'Happiness_Index(1-10)':\n",
    "        print(f\"  {var}: {corr:.4f}\")\n",
    "\n",
    "# 3.3 Statistical Significance Testing\n",
    "print(\"\\nðŸ“ˆ Statistical Significance Tests:\")\n",
    "\n",
    "# Test correlation between Days Without Social Media and Stress\n",
    "stress_corr, stress_p = pearsonr(df['Days_Without_Social_Media'], df['Stress_Level(1-10)'])\n",
    "print(f\"Days Without Social Media vs Stress Level:\")\n",
    "print(f\"  Pearson r: {stress_corr:.4f} (p-value: {stress_p:.4e})\")\n",
    "\n",
    "# Test correlation between Days Without Social Media and Happiness\n",
    "happiness_corr, happiness_p = pearsonr(df['Days_Without_Social_Media'], df['Happiness_Index(1-10)'])\n",
    "print(f\"Days Without Social Media vs Happiness Index:\")\n",
    "print(f\"  Pearson r: {happiness_corr:.4f} (p-value: {happiness_p:.4e})\")\n",
    "\n",
    "# Test correlation between Screen Time and Stress\n",
    "screen_stress_corr, screen_stress_p = pearsonr(df['Daily_Screen_Time(hrs)'], df['Stress_Level(1-10)'])\n",
    "print(f\"Daily Screen Time vs Stress Level:\")\n",
    "print(f\"  Pearson r: {screen_stress_corr:.4f} (p-value: {screen_stress_p:.4e})\")\n",
    "\n",
    "print(\"âœ… Correlation analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ef8233",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Phase 4: Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb5b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Simple Linear Regression\n",
    "print(\"ðŸ“ˆ REGRESSION ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "X = df[['Days_Without_Social_Media']]\n",
    "y_stress = df['Stress_Level(1-10)']\n",
    "y_happiness = df['Happiness_Index(1-10)']\n",
    "\n",
    "# Stress Model\n",
    "lr_stress = LinearRegression()\n",
    "lr_stress.fit(X, y_stress)\n",
    "stress_pred = lr_stress.predict(X)\n",
    "\n",
    "print(\"Simple Linear Regression Results:\")\n",
    "print(f\"\\nStress Model:\")\n",
    "print(f\"  Coefficient: {lr_stress.coef_[0]:.4f}\")\n",
    "print(f\"  Intercept: {lr_stress.intercept_:.4f}\")\n",
    "print(f\"  RÂ² Score: {r2_score(y_stress, stress_pred):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_stress, stress_pred):.4f}\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_stress, stress_pred)):.4f}\")\n",
    "\n",
    "# Happiness Model\n",
    "lr_happiness = LinearRegression()\n",
    "lr_happiness.fit(X, y_happiness)\n",
    "happiness_pred = lr_happiness.predict(X)\n",
    "\n",
    "print(f\"\\nHappiness Model:\")\n",
    "print(f\"  Coefficient: {lr_happiness.coef_[0]:.4f}\")\n",
    "print(f\"  Intercept: {lr_happiness.intercept_:.4f}\")\n",
    "print(f\"  RÂ² Score: {r2_score(y_happiness, happiness_pred):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_happiness, happiness_pred):.4f}\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_happiness, happiness_pred)):.4f}\")\n",
    "\n",
    "# 4.2 Multiple Regression with Control Variables\n",
    "print(\"\\nðŸ”¬ Multiple Regression (with confounders):\")\n",
    "\n",
    "features = ['Days_Without_Social_Media', 'Daily_Screen_Time(hrs)', 'Sleep_Quality(1-10)', \n",
    "           'Exercise_Frequency(week)', 'Age']\n",
    "\n",
    "X_multi = df[features]\n",
    "X_multi_with_const = sm.add_constant(X_multi)\n",
    "\n",
    "# Stress Model with statsmodels for detailed diagnostics\n",
    "model_stress_multi = sm.OLS(y_stress, X_multi_with_const).fit()\n",
    "print(\"\\nMultiple Regression - Stress Level:\")\n",
    "print(model_stress_multi.summary())\n",
    "\n",
    "# Happiness Model\n",
    "model_happiness_multi = sm.OLS(y_happiness, X_multi_with_const).fit()\n",
    "print(\"\\nMultiple Regression - Happiness Index:\")\n",
    "print(model_happiness_multi.summary())\n",
    "\n",
    "# 4.3 Visualization of Regression Results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Stress\n",
    "axes[0].scatter(df['Days_Without_Social_Media'], df['Stress_Level(1-10)'], \n",
    "                alpha=0.3, s=10, label='Actual')\n",
    "axes[0].plot(df['Days_Without_Social_Media'], stress_pred, \n",
    "             color='red', linewidth=2, label='Predicted')\n",
    "axes[0].set_xlabel('Days Without Social Media')\n",
    "axes[0].set_ylabel('Stress Level')\n",
    "axes[0].set_title(f'Linear Regression: Stress (RÂ² = {r2_score(y_stress, stress_pred):.3f})')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Happiness\n",
    "axes[1].scatter(df['Days_Without_Social_Media'], df['Happiness_Index(1-10)'], \n",
    "                alpha=0.3, s=10, label='Actual')\n",
    "axes[1].plot(df['Days_Without_Social_Media'], happiness_pred, \n",
    "             color='green', linewidth=2, label='Predicted')\n",
    "axes[1].set_xlabel('Days Without Social Media')\n",
    "axes[1].set_ylabel('Happiness Index')\n",
    "axes[1].set_title(f'Linear Regression: Happiness (RÂ² = {r2_score(y_happiness, happiness_pred):.3f})')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/04_regression_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Regression analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055efcb",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Phase 5: User Segmentation (Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69d43dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Prepare Data for Clustering\n",
    "print(\"ðŸŽ¯ USER SEGMENTATION ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Select features for clustering\n",
    "clustering_features = ['Days_Without_Social_Media', 'Daily_Screen_Time(hrs)', 'Sleep_Quality(1-10)',\n",
    "                       'Exercise_Frequency(week)', 'Stress_Level(1-10)', 'Happiness_Index(1-10)', 'Age']\n",
    "\n",
    "X_cluster = df[clustering_features]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_cluster)\n",
    "\n",
    "print(f\"Clustering data shape: {X_scaled.shape}\")\n",
    "print(f\"Features used: {clustering_features}\")\n",
    "\n",
    "# 5.2 Elbow Method for Optimal K\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)   \n",
    "    kmeans.fit(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
    "\n",
    "# Plot elbow curve\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(K_range, inertias, marker='o', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Number of Clusters (K)')\n",
    "axes[0].set_ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
    "axes[0].set_title('Elbow Method for Optimal K')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(K_range, silhouette_scores, marker='o', linewidth=2, markersize=8, color='green')\n",
    "axes[1].set_xlabel('Number of Clusters (K)')\n",
    "axes[1].set_ylabel('Silhouette Score')\n",
    "axes[1].set_title('Silhouette Analysis')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/05_clustering_optimization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Optimal K selection\n",
    "optimal_k = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nOptimal number of clusters: {optimal_k}\")\n",
    "print(f\"Best silhouette score: {max(silhouette_scores):.4f}\")\n",
    "\n",
    "# 5.3 Apply K-Means with Optimal K\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df['Cluster_KMeans'] = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(df['Cluster_KMeans'].value_counts().sort_index())\n",
    "\n",
    "# 5.4 Cluster Profiling\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CLUSTER PROFILES (K-Means)\")\n",
    "print('='*60)\n",
    "\n",
    "for cluster_id in range(optimal_k):\n",
    "    cluster_data = df[df['Cluster_KMeans'] == cluster_id]\n",
    "    print(f\"\\n--- Cluster {cluster_id} (n={len(cluster_data)}) ---\")\n",
    "    print(cluster_data[clustering_features].mean().round(2))\n",
    "\n",
    "# 5.5 PCA Visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], \n",
    "                     c=df['Cluster_KMeans'], \n",
    "                     cmap='viridis', s=100, alpha=0.6, edgecolors='black')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "plt.title('K-Means Clustering: PCA Visualization')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('results/06_kmeans_clusters.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 5.6 DBSCAN Clustering\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DBSCAN CLUSTERING\")\n",
    "print('='*60)\n",
    "\n",
    "dbscan = DBSCAN(eps=0.8, min_samples=5)\n",
    "df['Cluster_DBSCAN'] = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "print(f\"\\nDBSCAN Cluster distribution:\")\n",
    "print(f\"Number of clusters: {len(set(df['Cluster_DBSCAN'])) - (1 if -1 in df['Cluster_DBSCAN'] else 0)}\")\n",
    "print(f\"Number of noise points: {sum(df['Cluster_DBSCAN'] == -1)}\")\n",
    "print(df['Cluster_DBSCAN'].value_counts().sort_index())\n",
    "\n",
    "# DBSCAN Visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], \n",
    "                     c=df['Cluster_DBSCAN'], \n",
    "                     cmap='plasma', s=100, alpha=0.6, edgecolors='black')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "plt.title('DBSCAN Clustering: PCA Visualization')\n",
    "plt.colorbar(scatter, label='Cluster (-1 = Noise)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('results/07_dbscan_clusters.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Clustering analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bd9a2a",
   "metadata": {},
   "source": [
    "# ðŸ§  Phase 6: Advanced Modeling (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d193144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Prepare Data for Advanced Modeling\n",
    "print(\"ðŸ§  ADVANCED MODELING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "df_encoded = df.copy()\n",
    "df_encoded['Gender'] = le.fit_transform(df_encoded['Gender'])\n",
    "df_encoded['Social_Media_Platform'] = le.fit_transform(df_encoded['Social_Media_Platform'])\n",
    "\n",
    "# Features and targets\n",
    "features = ['Age', 'Gender', 'Daily_Screen_Time(hrs)', 'Sleep_Quality(1-10)', \n",
    "           'Days_Without_Social_Media', 'Exercise_Frequency(week)', 'Social_Media_Platform']\n",
    "X = df_encoded[features]\n",
    "y_stress = df_encoded['Stress_Level(1-10)']\n",
    "y_happiness = df_encoded['Happiness_Index(1-10)']\n",
    "\n",
    "print(f\"Features used: {features}\")\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "\n",
    "# 6.2 Random Forest Modeling\n",
    "# Split data\n",
    "X_train, X_test, y_train_stress, y_test_stress = train_test_split(X, y_stress, test_size=0.2, random_state=42)\n",
    "X_train_h, X_test_h, y_train_happiness, y_test_happiness = train_test_split(X, y_happiness, test_size=0.2, random_state=42)\n",
    "\n",
    "# Stress Model\n",
    "rf_stress = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_stress.fit(X_train, y_train_stress)\n",
    "rf_stress_pred = rf_stress.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"\\nStress Level Prediction:\")\n",
    "print(f\"  RÂ² Score: {r2_score(y_test_stress, rf_stress_pred):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test_stress, rf_stress_pred):.4f}\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test_stress, rf_stress_pred)):.4f}\")\n",
    "\n",
    "# Happiness Model\n",
    "rf_happiness = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_happiness.fit(X_train_h, y_train_happiness)\n",
    "rf_happiness_pred = rf_happiness.predict(X_test_h)\n",
    "\n",
    "print(f\"\\nHappiness Index Prediction:\")\n",
    "print(f\"  RÂ² Score: {r2_score(y_test_happiness, rf_happiness_pred):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test_happiness, rf_happiness_pred):.4f}\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test_happiness, rf_happiness_pred)):.4f}\")\n",
    "\n",
    "# 6.3 Feature Importance Analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Stress feature importance\n",
    "stress_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf_stress.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "axes[0].barh(stress_importance['feature'], stress_importance['importance'])\n",
    "axes[0].set_title('Feature Importance: Stress Level Prediction')\n",
    "axes[0].set_xlabel('Importance')\n",
    "\n",
    "# Happiness feature importance\n",
    "happiness_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf_happiness.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "axes[1].barh(happiness_importance['feature'], happiness_importance['importance'])\n",
    "axes[1].set_title('Feature Importance: Happiness Index Prediction')\n",
    "axes[1].set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/08_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 6.4 Model Performance Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Stress predictions\n",
    "axes[0].scatter(y_test_stress, rf_stress_pred, alpha=0.6)\n",
    "axes[0].plot([1, 10], [1, 10], 'r--', linewidth=2)\n",
    "axes[0].set_xlabel('Actual Stress Level')\n",
    "axes[0].set_ylabel('Predicted Stress Level')\n",
    "axes[0].set_title(f'Random Forest: Stress Prediction (RÂ² = {r2_score(y_test_stress, rf_stress_pred):.3f})')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Happiness predictions\n",
    "axes[1].scatter(y_test_happiness, rf_happiness_pred, alpha=0.6, color='green')\n",
    "axes[1].plot([1, 10], [1, 10], 'r--', linewidth=2)\n",
    "axes[1].set_xlabel('Actual Happiness Index')\n",
    "axes[1].set_ylabel('Predicted Happiness Index')\n",
    "axes[1].set_title(f'Random Forest: Happiness Prediction (RÂ² = {r2_score(y_test_happiness, rf_happiness_pred):.3f})')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/09_rf_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Advanced modeling complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a74ff0",
   "metadata": {},
   "source": [
    "# ðŸ“Š Phase 7: Comprehensive Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91448c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Compile Results\n",
    "print(\"ðŸ“Š COMPREHENSIVE RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_summary = {\n",
    "    'Analysis': [\n",
    "        'Dataset Size',\n",
    "        'Key Correlation (Days vs Stress)',\n",
    "        'Key Correlation (Days vs Happiness)',\n",
    "        'Simple Regression RÂ² (Stress)',\n",
    "        'Simple Regression RÂ² (Happiness)',\n",
    "        'Multiple Regression RÂ² (Stress)',\n",
    "        'Multiple Regression RÂ² (Happiness)',\n",
    "        'Optimal K-Means Clusters',\n",
    "        'Best Silhouette Score',\n",
    "        'Random Forest RÂ² (Stress)',\n",
    "        'Random Forest RÂ² (Happiness)',\n",
    "        'Most Important Feature (Stress)',\n",
    "        'Most Important Feature (Happiness)'\n",
    "    ],\n",
    "    'Result': [\n",
    "        f'{df.shape[0]} users',\n",
    "        f'{stress_corr:.4f}',\n",
    "        f'{happiness_corr:.4f}',\n",
    "        f'{r2_score(y_stress, stress_pred):.4f}',\n",
    "        f'{r2_score(y_happiness, happiness_pred):.4f}',\n",
    "        f'{model_stress_multi.rsquared:.4f}',\n",
    "        f'{model_happiness_multi.rsquared:.4f}',\n",
    "        f'{optimal_k}',\n",
    "        f'{max(silhouette_scores):.4f}',\n",
    "        f'{r2_score(y_test_stress, rf_stress_pred):.4f}',\n",
    "        f'{r2_score(y_test_happiness, rf_happiness_pred):.4f}',\n",
    "        f'{stress_importance.iloc[-1][\"feature\"]}',\n",
    "        f'{happiness_importance.iloc[-1][\"feature\"]}'\n",
    "    ]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('results/final_results_summary.csv', index=False)\n",
    "\n",
    "# 7.2 Key Insights\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ðŸŽ¯ KEY INSIGHTS\")\n",
    "print('='*60)\n",
    "\n",
    "print(\"1. CORRELATION ANALYSIS:\")\n",
    "print(f\"   â€¢ Days without social media shows {abs(stress_corr):.3f} correlation with stress levels\")\n",
    "print(f\"   â€¢ Days without social media shows {abs(happiness_corr):.3f} correlation with happiness\")\n",
    "print(f\"   â€¢ Screen time shows {abs(screen_stress_corr):.3f} correlation with stress\")\n",
    "\n",
    "print(\"\\n2. PREDICTIVE MODELING:\")\n",
    "print(f\"   â€¢ Random Forest achieves {r2_score(y_test_stress, rf_stress_pred):.1%} accuracy for stress prediction\")\n",
    "print(f\"   â€¢ Random Forest achieves {r2_score(y_test_happiness, rf_happiness_pred):.1%} accuracy for happiness prediction\")\n",
    "\n",
    "print(\"\\n3. USER SEGMENTATION:\")\n",
    "print(f\"   â€¢ Identified {optimal_k} distinct user clusters with silhouette score of {max(silhouette_scores):.3f}\")\n",
    "print(f\"   â€¢ Most important predictor for stress: {stress_importance.iloc[-1]['feature']}\")\n",
    "print(f\"   â€¢ Most important predictor for happiness: {happiness_importance.iloc[-1]['feature']}\")\n",
    "\n",
    "print(\"\\n4. PRACTICAL IMPLICATIONS:\")\n",
    "print(\"   â€¢ Social media abstinence appears beneficial for mental health\")\n",
    "print(\"   â€¢ Sleep quality and exercise are strong protective factors\")\n",
    "print(\"   â€¢ Personalized interventions should consider user phenotypes\")\n",
    "\n",
    "# 7.3 Save Processed Dataset\n",
    "df.to_csv('results/processed_dataset_with_clusters.csv', index=False)\n",
    "print(\"\\nðŸ’¾ All results and processed data saved to 'results/' directory\")\n",
    "\n",
    "print(\"\\nâœ… COMPREHENSIVE ANALYSIS COMPLETE!\")\n",
    "print(\"ðŸŽ‰ Your Social Media Detox Effect Analyzer is ready for portfolio presentation!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
